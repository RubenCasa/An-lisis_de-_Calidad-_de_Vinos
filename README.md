# Anlisis de Calidad dem Vinos
Implementaci√≥n y an√°lisis comparativo de modelos de ML sobre el dataset Wine Quality. Demostr√© la superioridad de LDA en clasificaci√≥n (75.6% Accuracy) y contrast√© Ridge vs Lasso en regresi√≥n, destacando la capacidad de Lasso para la selecci√≥n de caracter√≠sticas clave.

# üç∑ An√°lisis de Calidad de Vinos: Clasificaci√≥n y Regresi√≥n Regularizada

¬°Hola! Soy **Rub√©n**, Ingeniero en Ciencias de Datos e Inteligencia Artificial.

En este repositorio comparto un proyecto pr√°ctico donde analizo el dataset **"Wine Quality"** para predecir la calidad del vino bas√°ndome en sus propiedades fisicoqu√≠micas. El objetivo principal no fue solo obtener m√©tricas, sino entender el comportamiento de diferentes algoritmos frente a datos reales correlacionados.

## üöÄ Resumen del Proyecto

El trabajo se divide en dos enfoques principales:
1.  **Clasificaci√≥n:** Determinar si un vino es "bueno" o "malo".
2.  **Regresi√≥n:** Predecir el puntaje exacto de calidad.

Para ello, realic√© una comparaci√≥n t√©cnica entre modelos probabil√≠sticos y modelos de regularizaci√≥n.

## üìä Principales Hallazgos

A continuaci√≥n, detallo las conclusiones m√°s relevantes a las que llegu√© tras el entrenamiento y evaluaci√≥n:

### 1. Clasificaci√≥n: ¬øGNB o LDA?
Puse a prueba **Gaussian Naive Bayes (GNB)** contra **Linear Discriminant Analysis (LDA)**.
* **El Ganador:** LDA fue superior con un **Accuracy del 75.6%** (frente al 72.2% de GNB).
* **¬øPor qu√©?** El an√°lisis de correlaci√≥n mostr√≥ que las variables del vino no son independientes (ej. acidez fija vs. pH). GNB asume independencia, y al violarse esta suposici√≥n, su rendimiento cae. LDA, en cambio, maneja mejor estas relaciones entre variables.

### 2. Regresi√≥n Regularizada: Ridge vs. Lasso
Evalu√© modelos lineales con penalizaci√≥n L1 (Lasso) y L2 (Ridge) para evitar el sobreajuste.
* **El Ganador en Predicci√≥n:** **Ridge (alpha=100)** logr√≥ el menor error (**RMSE: 0.6266**) y un mejor R¬≤.
* **El Valor de Lasso:** Aunque tuvo un error ligeramente mayor (**RMSE: 0.6625**), Lasso fue extremadamente √∫til para la **selecci√≥n de caracter√≠sticas**. De las 11 variables originales, Lasso elimin√≥ 8 (llevando sus coeficientes a 0), destacando que los factores m√°s determinantes para la calidad son:
    * Alcohol (+)
    * Volatile Acidity (-)
    * Sulphates (+)

## üõ†Ô∏è Tecnolog√≠as Utilizadas
* **Python**
* **Pandas & NumPy** (Manipulaci√≥n de datos)
* **Matplotlib & Seaborn** (Visualizaci√≥n y matrices de confusi√≥n)
* **Scikit-Learn** (Modelado, GridSearchCV y Preprocesamiento)

---
*Este proyecto fue desarrollado como parte de mi formaci√≥n continua en Machine Learning. Si tienes sugerencias o dudas sobre el c√≥digo, ¬°no dudes en contactarme!*
